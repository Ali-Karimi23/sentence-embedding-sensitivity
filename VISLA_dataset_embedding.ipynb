{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f7c4c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datasets import load_dataset, load_from_disk , Dataset, DatasetDict\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "639d437b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "\n",
    "# Mount Drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb20cd68",
   "metadata": {},
   "outputs": [],
   "source": [
    "REPO = \"/content/drive/MyDrive/00-github/sentence-embedding-sensitivity\"\n",
    "DATA = os.path.join(REPO,\"Data\")\n",
    "DATASETS_SAVE_PATH = os.path.join(DATA,\"visla_datasets\")\n",
    "GEN_DATA = os.path.join(REPO,\"VISLA\",\"Generic_VISLA.tsv\")\n",
    "SPA_DATA = os.path.join(REPO,\"VISLA\",\"Spatial_VISLA.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "072cd9bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dict = {\n",
    "    \"par-dis-roberta\": \"paraphrase-distilroberta-base-v1\",\n",
    "    \"roberta-base-v3\": \"msmarco-roberta-base-v3\",\n",
    "    \"par-mpnet\": \"paraphrase-mpnet-base-v2\",\n",
    "    \"par-xlm-r\": \"paraphrase-xlm-r-multilingual-v1\",\n",
    "    \"labse\": \"LaBSE\",\n",
    "    \"e5-base\": \"intfloat/e5-base-v2\",\n",
    "    \"gte-base\": \"thenlper/gte-base\",\n",
    "    \"bge-base-v15\": \"BAAI/bge-base-en-v1.5\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed1da2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title make dataset folder\n",
    "os.makedirs(DATASETS_SAVE_PATH, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b7618d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title load generic dataset\n",
    "generic_df = pd.read_csv(GEN_DATA, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d431a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title  Fast GPU modes\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "if device == \"cuda\":\n",
    "    torch.backends.cuda.matmul.allow_tf32 = True\n",
    "    torch.backends.cudnn.allow_tf32 = True\n",
    "    torch.set_float32_matmul_precision(\"high\")\n",
    "    gpu_name = torch.cuda.get_device_name(0)\n",
    "    ENCODE_BS = 1024 if \"A100\" in gpu_name else 256\n",
    "    AMP_DTYPE = torch.bfloat16 if \"A100\" in gpu_name else torch.float16\n",
    "else:\n",
    "    gpu_name = \"CPU\"\n",
    "    ENCODE_BS = 64\n",
    "    AMP_DTYPE = None\n",
    "\n",
    "print(f\"Running on {gpu_name}, batch_size={ENCODE_BS}, dtype={AMP_DTYPE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e4597c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_name, model_id in model_dict.items():\n",
    "    print(f\"Model {model_name} is on processing...\")\n",
    "    model = SentenceTransformer(model_id, device=device)\n",
    "    model.eval()\n",
    "    if device == \"cuda\":\n",
    "        try:\n",
    "            base = model._first_module().auto_model\n",
    "            base.to(dtype=AMP_DTYPE, device=device)\n",
    "        except Exception:\n",
    "            pass\n",
    "    caption = generic_df[\"caption\"].tolist()\n",
    "    positive_sent = generic_df[\"second positive\"].tolist()\n",
    "    negative_sent = generic_df[\"negative-caption\"].tolist()\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        with torch.autocast(device_type=device, dtype=AMP_DTYPE):\n",
    "            # Encode sentences\n",
    "            t1 = time.time()\n",
    "            embA = model.encode(\n",
    "                caption,\n",
    "                batch_size=ENCODE_BS,\n",
    "                convert_to_numpy=True,\n",
    "                show_progress_bar=True,\n",
    "                normalize_embeddings=True,\n",
    "            )\n",
    "            embB = model.encode(\n",
    "                positive_sent,\n",
    "                batch_size=ENCODE_BS,\n",
    "                convert_to_numpy=True,\n",
    "                show_progress_bar=True,\n",
    "                normalize_embeddings=True,\n",
    "            )\n",
    "            embC = model.encode(\n",
    "                negative_sent,\n",
    "                batch_size=ENCODE_BS,\n",
    "                convert_to_numpy=True,\n",
    "                show_progress_bar=True,\n",
    "                normalize_embeddings=True,\n",
    "            )\n",
    "            t2 = time.time()\n",
    "            print(f\"Encoded in {t2-t1:.1f} seconds\")\n",
    "            print(\n",
    "                f\"Embeddings: {embA.shape}, {embB.shape}, {embC.shape}, dtype={embA.dtype}\"\n",
    "            )\n",
    "\n",
    "            # Calculate cosine similarity\n",
    "            t1 = time.time()\n",
    "            cosine_scores_pos = np.sum(embA * embB, axis=1)\n",
    "            cosine_scores_neg = np.sum(embA * embC, axis=1)\n",
    "            cosine_scores = cosine_scores_pos - cosine_scores_neg\n",
    "            t2 = time.time()\n",
    "            print(f\"Calculated cosine similarity in {t2-t1:.1f} seconds\")\n",
    "            print(\n",
    "                f\"Cosine scores: min {cosine_scores.min():.4f}, max {cosine_scores.max():.4f}, mean {cosine_scores.mean():.4f}, std {cosine_scores.std():.4f}\"\n",
    "            )\n",
    "            save_path = os.path.join(\n",
    "                DATASETS_SAVE_PATH, f\"VISLA_generic_{model_name}.npz\"\n",
    "            )\n",
    "            np.savez_compressed(\n",
    "                save_path,\n",
    "                embedding1=embA.astype(np.float16),\n",
    "                embedding2=embB.astype(np.float16),\n",
    "                embedding3=embC.astype(np.float16),\n",
    "                cosine_scores_pos=cosine_scores_pos.astype(np.float16),\n",
    "                cosine_scores_neg=cosine_scores_neg.astype(np.float16),\n",
    "                cosine_scores=cosine_scores.astype(np.float16),\n",
    "            )\n",
    "            print(f\"Saved to {save_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sentence_transformer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
