{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf2813f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from datasets import load_dataset, load_from_disk\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf463d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "\n",
    "# Mount Drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e02c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "REPO = \"content/drive/MyDrive/00-github/sentence-embedding-sensitivity\"\n",
    "DATA = os.path.join(REPO,\"Data\")\n",
    "DATASETS = os.path.join(DATA,\"datasets\")\n",
    "SICK_DATA = os.path.join(DATA,\"sick_dataset\")\n",
    "SR_DATA = os.path.join(DATA,\"sr_dataset\")\n",
    "VISLA_DATA = os.path.join(DATA,\"VISLA\")\n",
    "\n",
    "model_dict = {\n",
    "    \"par_dis_roberta\": \"paraphrase-distilroberta-base-v1\",\n",
    "    \"roberta_base_v3\": \"msmarco-roberta-base-v3\",\n",
    "    \"par_mpnet\": \"paraphrase-mpnet-base-v2\",\n",
    "    \"par_xlm_r\": \"paraphrase-xlm-r-multilingual-v1\",\n",
    "    \"labse\": \"LaBSE\",\n",
    "    \"e5_base\": \"intfloat/e5-base-v2\",\n",
    "    \"gte_base\": \"thenlper/gte-base\",\n",
    "    \"bge_base_v15\": \"BAAI/bge-base-en-v1.5\"\n",
    "}\n",
    "\n",
    "benchmark_datasets = {\n",
    "    \"MRPC\": (\"glue\", \"mrpc\"),\n",
    "    \"QQP\": (\"glue\", \"qqp\"),\n",
    "    \"PAWS\": (\"paws\", \"labeled_final\"),\n",
    "    \"STS-B\": (\"glue\", \"stsb\"),\n",
    "    \"SICK\": f\"{SICK_DATA}\",\n",
    "    \"SR\": f\"{SR_DATA}\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52817ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title  Fast GPU modes\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "if device == \"cuda\":\n",
    "    torch.backends.cuda.matmul.allow_tf32 = True\n",
    "    torch.backends.cudnn.allow_tf32 = True\n",
    "    torch.set_float32_matmul_precision(\"high\")\n",
    "    gpu_name = torch.cuda.get_device_name(0)\n",
    "    ENCODE_BS = 512 if \"A100\" in gpu_name else 256\n",
    "    AMP_DTYPE = torch.bfloat16 if \"A100\" in gpu_name else torch.float16\n",
    "else:\n",
    "    gpu_name = \"CPU\"\n",
    "    ENCODE_BS = 64\n",
    "    AMP_DTYPE = None\n",
    "\n",
    "print(f\"Running on {gpu_name}, batch_size={ENCODE_BS}, dtype={AMP_DTYPE}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sentence_transformer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
